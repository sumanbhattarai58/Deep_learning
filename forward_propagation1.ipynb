{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "198b49d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a neural network from scratch and code how it performs predictions using forward propagation\n",
    "#understanding neural networks and how they work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46d263a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73394995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89 0.08 0.12 0.02 0.93 0.02]\n",
      "[0.27 0.25 0.01]\n"
     ]
    }
   ],
   "source": [
    "#randomly initializing the weights and the biases in the network\n",
    "#6 weights and 3 biases, one for each node in the hidden layer as well as output layer\n",
    "weights= np.around(np.random.uniform(size=6), decimals=2)\n",
    "biases= np.around(np.random.uniform(size=3), decimals=2)\n",
    "print (weights)\n",
    "print(biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71de3aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 is 0.5 and x2 is 0.85\n"
     ]
    }
   ],
   "source": [
    "#let's compute the output for a given input, x1 and x2\n",
    "x1=0.5\n",
    "x2=0.85\n",
    "print(f\"x1 is {x1} and x2 is {x2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dac7a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weighted sum of the inputs at the first node in the hidden layer is 0.783 \n"
     ]
    }
   ],
   "source": [
    "#computing the weighted sum of the inputs z11,cat the first node of the hidden layer\n",
    "z11=x1 * weights[0] + x2 * weights[1] + biases[0]\n",
    "print(f\"The weighted sum of the inputs at the first node in the hidden layer is {z11} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfabc74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weighted sum of the inputs at the second node in he hidden layer is 0.327  \n"
     ]
    }
   ],
   "source": [
    "#computing the weighted sum of the inputs z12 at the second node of the hidden layer\n",
    "z12= x1 * weights[2] + x2 * weights[3] + biases[1]\n",
    "print(f\"The weighted sum of the inputs at the second node in he hidden layer is {z12}  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86ea9b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The activation of the first node in the hidden layer is 0.6863\n"
     ]
    }
   ],
   "source": [
    "#Assuming a sigmoid activation function, lets compute the activation of the first node a11, in the hidden layer\n",
    "a11=1.0/(1.0 + np.exp(-z11))\n",
    "a11= np.around(a11, decimals=4)\n",
    "print(f'The activation of the first node in the hidden layer is {a11}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83fbf6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The activation of the second node in the hidden layer is 0.581\n"
     ]
    }
   ],
   "source": [
    "#computing the aactivation of the second node , a12, in the hidden layer\n",
    "a12=1.0/(1.0 + np.exp(-z12))\n",
    "a12= np.around(a12, decimals=4)\n",
    "print(f'The activation of the second node in the hidden layer is {a12}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17dfba49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weighted sum of the inputs at the node in the output layer is 0.6599\n"
     ]
    }
   ],
   "source": [
    "#now these activations will serve as the inputs to the output layer. \n",
    "#so, lets compute the weighted sum of these inputs to the node int the output layer.\n",
    "z2= a11 * weights[4] + a12 * weights[5] + biases[2]\n",
    "print('The weighted sum of the inputs at the node in the output layer is {}'.format(np.around(z2, decimals=4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ab5fae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output of the network for x1 = 0.5 and x2 = 0.85 is 0.6592\n"
     ]
    }
   ],
   "source": [
    "#let's compute the output of the network as the activation of the node in the output layer. Assign the value to a2.\n",
    "a2=1.0/(1.0 + np.exp(-z2))\n",
    "print('The output of the network for x1 = 0.5 and x2 = 0.85 is {}'.format(np.around(a2, decimals=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77be79dc",
   "metadata": {},
   "source": [
    "neural networks for real problems are composed of many hidden layers and many more nodes in each layer. So, we can't continue making predictions using this very inefficient approach of computing the weighted sum at each node and the activation of each node manually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6ced65",
   "metadata": {},
   "source": [
    "In order to code an automatic way of making predictions, let's generalize our network. A general network would take n inputs, would have many hidden layers, each hidden layer having m nodes, and would have an output layer. Although the network is showing one hidden layer, but we will code the network to have many hidden layers. Similarly, although the network shows an output layer with one node, we will code the network to have more than one node in the output layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "692a94b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now lets start formmally defining the structure of the network\n",
    "n=2   #number of inputs\n",
    "num_hidden_layers = 2  #number of hidden layers\n",
    "m=[2,2]    #number of nodes in each hidden layer\n",
    "num_nodes_output =1  #number of nodes in the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f82a608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layer_1': {'node_1': {'weights': array([0.47, 0.02]), 'bias': array([0.02])}, 'node_2': {'weights': array([0.27, 0.54]), 'bias': array([0.32])}}, 'layer_2': {'node_1': {'weights': array([0.05, 0.68]), 'bias': array([0.93])}, 'node_2': {'weights': array([0.86, 0.73]), 'bias': array([0.7])}}, 'output': {'node_1': {'weights': array([0.66, 0.08]), 'bias': array([0.46])}}}\n"
     ]
    }
   ],
   "source": [
    "#now, lets initialize the weights and the biases in the network to random numbers\n",
    "num_nodes_previous = n   #number of nodes in previous layer\n",
    "network = {}  #initialize network as an empty dictionary\n",
    "# loop through each layer and randomly initialize the weights and biases associated with each node\n",
    "# notice how we are adding 1 to the number of hidden layers in order to include the output layer\n",
    "for layer in range(num_hidden_layers + 1):\n",
    "    if layer ==num_hidden_layers:\n",
    "        layer_name= \"output\"\n",
    "        num_nodes= num_nodes_output\n",
    "    else:\n",
    "        layer_name= 'layer_{}'.format(layer+1)\n",
    "        num_nodes=m[layer]\n",
    "\n",
    "#initialize weights and biases associated with each node in the current layer\n",
    "    network[layer_name]={}\n",
    "    for node in range(num_nodes):\n",
    "        node_name = 'node_{}'.format(node+1)\n",
    "        network[layer_name][node_name] = {\n",
    "            'weights': np.around(np.random.uniform(size=num_nodes_previous), decimals=2),\n",
    "            'bias': np.around(np.random.uniform(size=1), decimals=2),\n",
    "        }\n",
    "    \n",
    "    num_nodes_previous = num_nodes\n",
    "    \n",
    "print(network) # print network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1696b1",
   "metadata": {},
   "source": [
    "So now with the above code, we are able to initialize the weights and the biases pertaining to any network of any number of hidden layers and number of nodes in each layer. But let's put this code in a function so that we are able to repetitively execute all this code whenever we want to construct a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "400d04eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_network(num_inputs, num_hidden_layers, num_nodes_hidden, num_nodes_output):\n",
    "    \n",
    "    num_nodes_previous = num_inputs # number of nodes in the previous layer\n",
    "\n",
    "    network = {}\n",
    "    \n",
    "    # loop through each layer and randomly initialize the weights and biases associated with each layer\n",
    "    for layer in range(num_hidden_layers + 1):\n",
    "        \n",
    "        if layer == num_hidden_layers:\n",
    "            layer_name = 'output' # name last layer in the network output\n",
    "            num_nodes = num_nodes_output\n",
    "        else:\n",
    "            layer_name = 'layer_{}'.format(layer + 1) # otherwise give the layer a number\n",
    "            num_nodes = num_nodes_hidden[layer] \n",
    "        \n",
    "        # initialize weights and bias for each node\n",
    "        network[layer_name] = {}\n",
    "        for node in range(num_nodes):\n",
    "            node_name = 'node_{}'.format(node+1)\n",
    "            network[layer_name][node_name] = {\n",
    "                'weights': np.around(np.random.uniform(size=num_nodes_previous), decimals=2),\n",
    "                'bias': np.around(np.random.uniform(size=1), decimals=2),\n",
    "            }\n",
    "    \n",
    "        num_nodes_previous = num_nodes\n",
    "\n",
    "    return network # return the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e227ecc",
   "metadata": {},
   "source": [
    "now using the initialize_network function to create the network that takes 5 inputs, has 3 hidden layers, has 3 nodes in the first layer,2 nodes in the second layer and 3 nodes in the third layer and has 1 node in the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f849f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_network = initialize_network(5,3,[3,2,3],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cea9267b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute weighted sum at each node\n",
    "def compute_weighted_sum(inputs, weights, bias):\n",
    "    return np.sum(inputs * weights) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "450be97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The inputs to the network are [0.15 0.74 0.26 0.53 0.01]\n"
     ]
    }
   ],
   "source": [
    "#now lets generate 5 inputs that we can feed to small network\n",
    "from random import seed\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(12)\n",
    "inputs = np.around(np.random.uniform(size=5), decimals=2)\n",
    "\n",
    "print('The inputs to the network are {}'.format(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf22842f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weighted sum at the first node in the hidden layer is 1.5176\n"
     ]
    }
   ],
   "source": [
    "node_weights = small_network['layer_1']['node_1']['weights']\n",
    "node_bias = small_network['layer_1']['node_1']['bias']\n",
    "\n",
    "weighted_sum = compute_weighted_sum(inputs, node_weights, node_bias)\n",
    "print('The weighted sum at the first node in the hidden layer is {}'.format(np.around(weighted_sum[0], decimals=4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c833a7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output of the first node in the hidden layer is 0.8202\n"
     ]
    }
   ],
   "source": [
    "#compute node activation\n",
    "def node_activation(weighted_sum):\n",
    "    return 1.0 / (1.0 + np.exp(-1 * weighted_sum))\n",
    "node_output  = node_activation(compute_weighted_sum(inputs, node_weights, node_bias))\n",
    "print('The output of the first node in the hidden layer is {}'.format(np.around(node_output[0], decimals=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6b366d",
   "metadata": {},
   "source": [
    "The final piece of building a neural network that can perform predictions is to put everything together. So let's create a function that applies the compute_weighted_sum and node_activation functions to each node in the network and propagates the data all the way to the output layer and outputs a prediction for each node in the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a82961d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagate(network, inputs):\n",
    "    \n",
    "    layer_inputs = list(inputs) # start with the input layer as the input to the first hidden layer\n",
    "    \n",
    "    for layer in network:\n",
    "        \n",
    "        layer_data = network[layer]\n",
    "        \n",
    "        layer_outputs = [] \n",
    "        for layer_node in layer_data:\n",
    "        \n",
    "            node_data = layer_data[layer_node]\n",
    "        \n",
    "            # compute the weighted sum and the output of each node at the same time \n",
    "            node_output = node_activation(compute_weighted_sum(layer_inputs, node_data['weights'], node_data['bias']))\n",
    "            layer_outputs.append(np.around(node_output[0], decimals=4))\n",
    "            \n",
    "        if layer != 'output':\n",
    "            print('The outputs of the nodes in hidden layer number {} is {}'.format(layer.split('_')[1], layer_outputs))\n",
    "    \n",
    "        layer_inputs = layer_outputs # set the output of this layer to be the input to next layer\n",
    "\n",
    "    network_predictions = layer_outputs\n",
    "    return network_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0addb705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The outputs of the nodes in hidden layer number 1 is [np.float64(0.8202), np.float64(0.805), np.float64(0.8154)]\n",
      "The outputs of the nodes in hidden layer number 2 is [np.float64(0.8761), np.float64(0.8167)]\n",
      "The outputs of the nodes in hidden layer number 3 is [np.float64(0.8133), np.float64(0.7173), np.float64(0.8275)]\n",
      "The predicted value by the network for the given input is 0.9067\n"
     ]
    }
   ],
   "source": [
    "predictions = forward_propagate(small_network, inputs)\n",
    "print('The predicted value by the network for the given input is {}'.format(np.around(predictions[0], decimals=4)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
