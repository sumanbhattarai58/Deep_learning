{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "252f3800",
   "metadata": {},
   "source": [
    " we will learn how to use the Keras library to build models for classificaiton problems. We will use the popular MNIST dataset, a dataset of images, for a change.\n",
    " The MNIST database, short for Modified National Institute of Standards and Technology database, is a large database of handwritten digits that is commonly used for training various image processing systems. The database is also widely used for training and testing in the field of machine learning.\n",
    " The MNIST database contains 60,000 training images and 10,000 testing images of digits written by high school students and employees of the United States Census Bureau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "37422fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0d22ce52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the data\n",
    "(X_train, y_train),(X_test, y_test)=mnist.load_data()\n",
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be41e505",
   "metadata": {},
   "source": [
    "The first number in the output tuple is the number of images, and the other two numbers are the size of the images in dataset. So, each image is 28 pixels by 28 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bddc934d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1efb5caaed0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Let's visualize the first image in the training set using Matplotlib's scripting layer.\n",
    "plt.imshow(X_train[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d136ad44",
   "metadata": {},
   "source": [
    "With conventional neural networks, we cannot feed in the image as input as is. So we need to flatten the images into one-dimensional vectors, each of size 1 x (28 x 28) = 1 x 784.\n",
    "784 inputs, one input for each pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "38d9489f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten images into one-dimensional vector\n",
    "num_pixels= X_train.shape[1] * X_train.shape[2]  ## find size of one-dimensional vector\n",
    "X_train= X_train.reshape(X_train.shape[0],num_pixels).astype('float32')\n",
    "X_test= X_test.reshape(X_test.shape[0],num_pixels).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0104b7db",
   "metadata": {},
   "source": [
    "Since pixel values can range from 0 to 255, let's normalize the vectors to be between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aac5c291",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train =X_train/255\n",
    "X_test= X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bbcc6a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "#for classification we need to divide our target variable into categories\n",
    "y_train=to_categorical(y_train)\n",
    "y_test=to_categorical(y_test)\n",
    "num_classes= y_test.shape[1]\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b7c79437",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a neural network\n",
    "def classification_model():\n",
    "    model=Sequential()\n",
    "    model.add(Input(shape=(num_pixels,)))\n",
    "    model.add(Dense(num_pixels,activation='relu'))\n",
    "    model.add(Dense(100,activation='relu'))\n",
    "    model.add(Dense(num_classes,activation='softmax'))\n",
    "\n",
    "    #compile model\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "40933f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 - 5s - 3ms/step - accuracy: 0.9438 - loss: 0.1861 - val_accuracy: 0.9707 - val_loss: 0.0956\n",
      "Epoch 2/10\n",
      "1875/1875 - 4s - 2ms/step - accuracy: 0.9750 - loss: 0.0782 - val_accuracy: 0.9760 - val_loss: 0.0775\n",
      "Epoch 3/10\n",
      "1875/1875 - 4s - 2ms/step - accuracy: 0.9833 - loss: 0.0527 - val_accuracy: 0.9805 - val_loss: 0.0673\n",
      "Epoch 4/10\n",
      "1875/1875 - 4s - 2ms/step - accuracy: 0.9868 - loss: 0.0405 - val_accuracy: 0.9790 - val_loss: 0.0736\n",
      "Epoch 5/10\n",
      "1875/1875 - 4s - 2ms/step - accuracy: 0.9904 - loss: 0.0305 - val_accuracy: 0.9742 - val_loss: 0.0946\n",
      "Epoch 6/10\n",
      "1875/1875 - 4s - 2ms/step - accuracy: 0.9912 - loss: 0.0269 - val_accuracy: 0.9816 - val_loss: 0.0736\n",
      "Epoch 7/10\n",
      "1875/1875 - 4s - 2ms/step - accuracy: 0.9923 - loss: 0.0228 - val_accuracy: 0.9787 - val_loss: 0.0966\n",
      "Epoch 8/10\n",
      "1875/1875 - 4s - 2ms/step - accuracy: 0.9944 - loss: 0.0182 - val_accuracy: 0.9810 - val_loss: 0.0778\n",
      "Epoch 9/10\n",
      "1875/1875 - 4s - 2ms/step - accuracy: 0.9946 - loss: 0.0176 - val_accuracy: 0.9788 - val_loss: 0.1032\n",
      "Epoch 10/10\n",
      "1875/1875 - 4s - 2ms/step - accuracy: 0.9947 - loss: 0.0164 - val_accuracy: 0.9805 - val_loss: 0.0907\n",
      "Accuracy: 0.9804999828338623% \n",
      " Error: 0.019500017166137695\n"
     ]
    }
   ],
   "source": [
    "#train and test the model\n",
    "model= classification_model()\n",
    "#fit the model\n",
    "model.fit(X_train,y_train, validation_data=(X_test,y_test),epochs=10, verbose =2)\n",
    "#evaluate the model\n",
    "scores= model.evaluate(X_test,y_test,verbose=0)\n",
    "print('Accuracy: {}% \\n Error: {}'.format(scores[1], 1 - scores[1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2b4718d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">615,440</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">78,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │       \u001b[38;5;34m615,440\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m78,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,084,852</span> (7.95 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,084,852\u001b[0m (7.95 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">694,950</span> (2.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m694,950\u001b[0m (2.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,389,902</span> (5.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,389,902\u001b[0m (5.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e3f791",
   "metadata": {},
   "source": [
    "Sometimes, you cannot afford to retrain your model everytime you want to use it, especially if you are limited on computational resources and training your model can take a long time. Therefore, with the Keras library, you can save your model after training. To do that, we use the save method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4fdf7fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"classification_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bafdd3",
   "metadata": {},
   "source": [
    "When you are ready to use your model again, you use the load_model function from keras.saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "97dc2ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 - 5s - 3ms/step - accuracy: 0.9954 - loss: 0.0145 - val_accuracy: 0.9766 - val_loss: 0.1292\n",
      "Epoch 2/10\n",
      "1875/1875 - 4s - 2ms/step - accuracy: 0.9963 - loss: 0.0120 - val_accuracy: 0.9818 - val_loss: 0.1017\n",
      "Epoch 3/10\n",
      "1875/1875 - 4s - 2ms/step - accuracy: 0.9953 - loss: 0.0149 - val_accuracy: 0.9818 - val_loss: 0.0996\n",
      "Epoch 4/10\n",
      "1875/1875 - 4s - 2ms/step - accuracy: 0.9965 - loss: 0.0114 - val_accuracy: 0.9799 - val_loss: 0.1028\n",
      "Epoch 5/10\n",
      "1875/1875 - 4s - 2ms/step - accuracy: 0.9965 - loss: 0.0115 - val_accuracy: 0.9804 - val_loss: 0.1099\n",
      "Epoch 6/10\n",
      "1875/1875 - 5s - 2ms/step - accuracy: 0.9963 - loss: 0.0130 - val_accuracy: 0.9822 - val_loss: 0.1096\n",
      "Epoch 7/10\n",
      "1875/1875 - 4s - 2ms/step - accuracy: 0.9970 - loss: 0.0099 - val_accuracy: 0.9821 - val_loss: 0.1296\n",
      "Epoch 8/10\n",
      "1875/1875 - 4s - 2ms/step - accuracy: 0.9969 - loss: 0.0120 - val_accuracy: 0.9787 - val_loss: 0.1191\n",
      "Epoch 9/10\n",
      "1875/1875 - 4s - 2ms/step - accuracy: 0.9975 - loss: 0.0084 - val_accuracy: 0.9823 - val_loss: 0.1222\n",
      "Epoch 10/10\n",
      "1875/1875 - 4s - 2ms/step - accuracy: 0.9969 - loss: 0.0107 - val_accuracy: 0.9804 - val_loss: 0.1384\n",
      "Accuracy_10_epochs: 0.9804999828338623% \n",
      " Accuracy_20_epochs: 0.980400025844574\n"
     ]
    }
   ],
   "source": [
    "pretrained_model= keras.saving.load_model('classification_model.keras')\n",
    "# Further train the loaded model\n",
    "pretrained_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, verbose=2)\n",
    "\n",
    "# evaluate the model\n",
    "scores_20_epochs = pretrained_model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Accuracy_10_epochs: {}% \\n Accuracy_20_epochs: {}'.format(scores[1], scores_20_epochs[1])) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
